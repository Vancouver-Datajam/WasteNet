{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c55489f09c334ddba555c2b0d60b8ea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1ed22c9ee47545ccb33fd4474be07ec8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_db2ddbb6a5e045358c6c0d8af1fbc72f",
              "IPY_MODEL_1e37c4d939454187aac5a4570a36c1d7"
            ]
          }
        },
        "1ed22c9ee47545ccb33fd4474be07ec8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db2ddbb6a5e045358c6c0d8af1fbc72f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7e43c7bb7a264548b341cadbd875047d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e5a7dc7c2195477d8fcc300d2a50ca2c"
          }
        },
        "1e37c4d939454187aac5a4570a36c1d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_14082977f20d4b85b653fadc2b98529d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 131MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dbe3a9ba3f3149e09ecfc61eedbcd7d6"
          }
        },
        "7e43c7bb7a264548b341cadbd875047d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e5a7dc7c2195477d8fcc300d2a50ca2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "14082977f20d4b85b653fadc2b98529d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dbe3a9ba3f3149e09ecfc61eedbcd7d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zubiamansoor/project_3/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EqKGRX7hcLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install torch torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqqC-i67jU8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55BlWgJpiu3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Headers\"\"\"\n",
        "import os\n",
        "import os.path as osp\n",
        "import time\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import datasets"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2djZNjG7tTa5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os.path as osp\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from __future__ import print_function\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import sys\n",
        "if sys.version_info[0] == 2:\n",
        "    import cPickle as pickle\n",
        "else:\n",
        "    import pickle\n",
        "\n",
        "import math\n",
        "\n",
        "from skimage.transform import resize\n",
        "import scipy\n",
        "\n",
        "\n",
        "np.random.seed(111)\n",
        "torch.cuda.manual_seed_all(111)\n",
        "torch.manual_seed(111)\n",
        "\n",
        "\n",
        "class Dataset_Gary(Dataset):\n",
        "\n",
        "\tdef __init__(self, root, fold=\"train\",\n",
        "\t\t\t\t transform=None, target_transform=None):\n",
        "\t\t\n",
        "\t\tfold = fold.lower()\n",
        "\n",
        "\t\tself.train = False\n",
        "\t\tself.test = False\n",
        "\t\tself.val = False\n",
        "\n",
        "\t\tif fold == \"train\":\n",
        "\t\t\tself.train = True\n",
        "\t\telif fold == \"test\":\n",
        "\t\t\tself.test = True\n",
        "\t\telif fold == \"val\":\n",
        "\t\t\tself.val = True\n",
        "\t\telse:\n",
        "\t\t\traise RuntimeError(\"Not train-val-test\")\n",
        "\n",
        "\n",
        "\t\tself.root = os.path.expanduser(root)\n",
        "\t\tself.transform = transform\n",
        "\t\tself.target_transform = target_transform\n",
        "\n",
        "\t\tfpath = self.root\n",
        "\n",
        "\t\t# now load the picked numpy arrays\n",
        "\t\tself.data = []\n",
        "\t\tif self.train:\n",
        "\t\t\tself.datalist_dir = os.path.join(self.root, 'train_list.txt')\n",
        "\t\tif self.val:\n",
        "\t\t\tself.datalist_dir = os.path.join(self.root, 'val_list.txt')\n",
        "\t\tif self.test:\n",
        "\t\t\tself.datalist_dir = os.path.join(self.root, 'test_list.txt')\n",
        "\n",
        "\t\twith open(self.datalist_dir, 'r') as f:\n",
        "\t\t\tfor line in f:\n",
        "\t\t\t\tif line[0] == '#' or len(line.strip()) == 0:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\tparams = line.strip().split()\n",
        "\t\t\t\tself.data.append({\n",
        "\t\t\t\t\t'file_name' : params[0],\n",
        "\t\t\t\t\t'label' : params[1],})\n",
        "\n",
        "\tdef __getitem__(self, index):\n",
        "\t\tlabel = self.data[index]['label']\n",
        "\t\tif label == 'cardboard':\n",
        "\t\t\ttarget = 0\n",
        "\t\tif label == 'glass':\n",
        "\t\t\ttarget = 1\n",
        "\t\tif label == 'metal':\n",
        "\t\t\ttarget = 2\n",
        "\t\tif label == 'paper':\n",
        "\t\t\ttarget = 3\n",
        "\t\tif label == 'plastic':\n",
        "\t\t\ttarget = 4\n",
        "\t\tif label == 'trash':\n",
        "\t\t\ttarget = 5\n",
        "\t\timg = plt.imread(osp.join(self.root, self.data[index]['label'], self.data[index]['file_name']))\n",
        "\n",
        "\t\t# doing this so that it is consistent with all other datasets\n",
        "\t\t# to return a PIL Image\n",
        "\t\timg = Image.fromarray(img)\n",
        "\n",
        "\t\tif self.transform is not None:\n",
        "\t\t\timg = self.transform(img)\n",
        "\n",
        "\t\tif self.target_transform is not None:\n",
        "\t\t\ttarget = self.target_transform(target)\n",
        "\n",
        "\t\treturn img, target\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.data)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUdo6AkH0maX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PreTrainedResNet(nn.Module):\n",
        "  def __init__(self, num_classes, feature_extracting):\n",
        "    super(PreTrainedResNet, self).__init__()\n",
        "    \n",
        "    self.resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "    if feature_extracting:\n",
        "      for param in self.resnet18.parameters():\n",
        "          param.requires_grad = False\n",
        "    \n",
        "    num_feats = self.resnet18.fc.in_features\n",
        "    \n",
        "    self.resnet18.fc =  nn.Linear(num_feats,num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.resnet18.forward(x)\n",
        "    return x\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujUNEVsEvWwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, criterion, epoch, num_epochs):\n",
        "  model.train()\n",
        "  epoch_loss = 0.0\n",
        "  epoch_acc = 0.0\n",
        "  \n",
        "  for batch_idx, (images, labels) in enumerate(dataloaders['train']):\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    images, labels = images.cuda(), labels.cuda()\n",
        "    \n",
        "    outputs = model.forward(images)\n",
        "    \n",
        "    loss = criterion(outputs, labels)\n",
        "    \n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += torch.sum(preds == labels).item()\n",
        "    \n",
        "  epoch_loss /= dataset_sizes['train']\n",
        "  epoch_acc /= dataset_sizes['train']\n",
        "  \n",
        "  print('TRAINING Epoch %d/%d Loss %.4f Accuracy %.4f' % (epoch, num_epochs, epoch_loss, epoch_acc))\n",
        "\n",
        "  return epoch_loss, epoch_acc\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md7WhEJ_1XGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.metrics as metric\n",
        "\n",
        "def test(model, criterion, repeats=2):\n",
        "  model.eval()\n",
        "  \n",
        "  test_loss = 0.0\n",
        "  test_acc = 0.0\n",
        "  f1_score = 0.0\n",
        "  f1_score_w = 0.0\n",
        "  conf_mat = np.zeros([len(class_names),len(class_names)])\n",
        "  with torch.no_grad():\n",
        "    for itr in range(repeats):\n",
        "      for batch_idx, (images, labels) in enumerate(dataloaders['test']):\n",
        "        #move to GPU\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "\n",
        "        #forward\n",
        "        outputs = model.forward(images)\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "        predlabels = preds.cpu().numpy()\n",
        "        labels_num = labels.cpu().numpy()\n",
        "        for ind,label in enumerate(labels_num):\n",
        "          conf_mat[label,predlabels[ind]] = conf_mat[label,predlabels[ind]] + 1\n",
        "        \n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        test_acc += torch.sum(preds == labels).item()\n",
        "          \n",
        "        f1_score += metric.f1_score(labels_num, predlabels,labels=[0,1,2,3,4,5], average='weighted', zero_division='warn')\n",
        "        f1_score_w += metric.f1_score(labels_num, predlabels,labels=[0,1,2,3,4,5], average='macro', zero_division='warn')\n",
        "\n",
        "    test_loss /= (dataset_sizes['test']*repeats)\n",
        "    test_acc /= (dataset_sizes['test']*repeats)\n",
        "    f1_score /= (dataset_sizes['test']*repeats)\n",
        "\n",
        "\n",
        "    print('Test Loss: %.4f Test Accuracy %.4f Weighted: %.4f Macro: %.4f' % (test_loss, test_acc, f1_score, f1_score_w))\n",
        "    return test_loss, test_acc, conf_mat\n",
        "\n",
        "\n",
        "def val(model, criterion, repeats=2):\n",
        "  model.eval()\n",
        "  \n",
        "  test_loss = 0.0\n",
        "  test_acc = 0.0\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for itr in range(repeats):\n",
        "      for batch_idx, (images, labels) in enumerate(dataloaders['val']):\n",
        "        #move to GPU\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "\n",
        "        #forward\n",
        "        outputs = model.forward(images)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        test_acc += torch.sum(preds == labels).item()\n",
        "\n",
        "    test_loss /= (dataset_sizes['val']*repeats)\n",
        "    test_acc /= (dataset_sizes['val']*repeats)\n",
        "\n",
        "    print('Val Loss: %.4f Val Accuracy %.4f' % (test_loss, test_acc))\n",
        "\n",
        "    return test_loss, test_acc"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsmSIWL8ovUw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627,
          "referenced_widgets": [
            "c55489f09c334ddba555c2b0d60b8ea1",
            "1ed22c9ee47545ccb33fd4474be07ec8",
            "db2ddbb6a5e045358c6c0d8af1fbc72f",
            "1e37c4d939454187aac5a4570a36c1d7",
            "7e43c7bb7a264548b341cadbd875047d",
            "e5a7dc7c2195477d8fcc300d2a50ca2c",
            "14082977f20d4b85b653fadc2b98529d",
            "dbe3a9ba3f3149e09ecfc61eedbcd7d6"
          ]
        },
        "outputId": "2c2a153c-7dfd-492f-8fa5-bfa2d488c0f3"
      },
      "source": [
        "\n",
        "NUM_EPOCHS = 25\n",
        "LEARNING_RATE = 0.001 \n",
        "BATCH_SIZE = 10\n",
        "RESNET_LAST_ONLY = False #Fine tunes only the last layer. Set to False to fine tune entire network\n",
        "\n",
        "root_path = 'dataset/'\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize(384),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(384),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# loading datasets with PyTorch ImageFolder\n",
        "image_datasets_train = Dataset_Gary(root_path, fold=\"train\",\n",
        "\t\t\t\t transform=data_transforms['train'], target_transform=None)\n",
        "\n",
        "image_datasets_val = Dataset_Gary(root_path, fold=\"val\",\n",
        "\t\t\t\t transform=data_transforms['test'], target_transform=None)\n",
        "\n",
        "image_datasets_test = Dataset_Gary(root_path, fold=\"test\",\n",
        "\t\t\t\t transform=data_transforms['test'], target_transform=None)\n",
        "\n",
        "# defining data loaders to load data using image_datasets and transforms, here we also specify batch size for the mini batch\n",
        "\n",
        "dataloader_train = torch.utils.data.DataLoader(image_datasets_train, batch_size=BATCH_SIZE,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "            \n",
        "dataloader_val = torch.utils.data.DataLoader(image_datasets_val, batch_size=BATCH_SIZE,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "\n",
        "dataloader_test = torch.utils.data.DataLoader(image_datasets_test, batch_size=BATCH_SIZE,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "\n",
        "dataloaders = {'train': dataloader_train, 'test': dataloader_test, 'val':dataloader_val}\n",
        "\n",
        "dataset_size_train = len(image_datasets_train)\n",
        "dataset_size_val = len(image_datasets_val)\n",
        "dataset_size_test = len(image_datasets_test)\n",
        "\n",
        "dataset_sizes = {'train': dataset_size_train, 'test': dataset_size_test, 'val':dataset_size_val}\n",
        "\n",
        "class_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
        "\n",
        "#Initialize the model\n",
        "model = PreTrainedResNet(len(class_names), RESNET_LAST_ONLY)\n",
        "model = model.cuda()\n",
        "\n",
        "#Setting the optimizer and loss criterion\n",
        "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9 , weight_decay=1e-3)\n",
        "\n",
        "weightlist = [1,1,1,1,1,4]\n",
        "weightlist = torch.Tensor(weightlist)\n",
        "weightlist = weightlist.cuda()\n",
        "criterion = nn.CrossEntropyLoss(weight = weightlist)\n",
        "\n",
        "train_loss_list =[]\n",
        "train_acc_list = []\n",
        "val_loss_list =[]\n",
        "val_acc_list = []\n",
        "\n",
        "#Begin Train\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  t1,t2 = train(model, optimizer, criterion, epoch+1, NUM_EPOCHS)\n",
        "  train_loss_list.append(t1)\n",
        "  train_acc_list.append(t2)\n",
        "  if (epoch+1) % 5 == 0:\n",
        "    t1,t2 = val(model, criterion)\n",
        "    val_loss_list.append(t1)\n",
        "    val_acc_list.append(t2)\n",
        "  \n",
        "print(\"Finished Training\")\n",
        "print(\"-\"*10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c55489f09c334ddba555c2b0d60b8ea1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "TRAINING Epoch 1/25 Loss 0.1137 Accuracy 0.5650\n",
            "TRAINING Epoch 2/25 Loss 0.0614 Accuracy 0.7800\n",
            "TRAINING Epoch 3/25 Loss 0.0474 Accuracy 0.8422\n",
            "TRAINING Epoch 4/25 Loss 0.0426 Accuracy 0.8586\n",
            "TRAINING Epoch 5/25 Loss 0.0275 Accuracy 0.9027\n",
            "Val Loss: 0.0320 Val Accuracy 0.8892\n",
            "TRAINING Epoch 6/25 Loss 0.0214 Accuracy 0.9282\n",
            "TRAINING Epoch 7/25 Loss 0.0222 Accuracy 0.9259\n",
            "TRAINING Epoch 8/25 Loss 0.0188 Accuracy 0.9367\n",
            "TRAINING Epoch 9/25 Loss 0.0192 Accuracy 0.9293\n",
            "TRAINING Epoch 10/25 Loss 0.0143 Accuracy 0.9491\n",
            "Val Loss: 0.0234 Val Accuracy 0.9182\n",
            "TRAINING Epoch 11/25 Loss 0.0093 Accuracy 0.9695\n",
            "TRAINING Epoch 12/25 Loss 0.0127 Accuracy 0.9559\n",
            "TRAINING Epoch 13/25 Loss 0.0081 Accuracy 0.9762\n",
            "TRAINING Epoch 14/25 Loss 0.0077 Accuracy 0.9774\n",
            "TRAINING Epoch 15/25 Loss 0.0081 Accuracy 0.9751\n",
            "Val Loss: 0.0130 Val Accuracy 0.9446\n",
            "TRAINING Epoch 16/25 Loss 0.0114 Accuracy 0.9621\n",
            "TRAINING Epoch 17/25 Loss 0.0085 Accuracy 0.9712\n",
            "TRAINING Epoch 18/25 Loss 0.0071 Accuracy 0.9762\n",
            "TRAINING Epoch 19/25 Loss 0.0083 Accuracy 0.9762\n",
            "TRAINING Epoch 20/25 Loss 0.0054 Accuracy 0.9870\n",
            "Val Loss: 0.0136 Val Accuracy 0.9499\n",
            "TRAINING Epoch 21/25 Loss 0.0055 Accuracy 0.9808\n",
            "TRAINING Epoch 22/25 Loss 0.0057 Accuracy 0.9791\n",
            "TRAINING Epoch 23/25 Loss 0.0070 Accuracy 0.9768\n",
            "TRAINING Epoch 24/25 Loss 0.0056 Accuracy 0.9813\n",
            "TRAINING Epoch 25/25 Loss 0.0052 Accuracy 0.9853\n",
            "Val Loss: 0.0127 Val Accuracy 0.9604\n",
            "Finished Training\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv9IOqoXozir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1,t2,conf_mat = test(model, criterion)\n",
        "print('Conf Mat\\n',conf_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rji12O1KTumN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(6):\n",
        "  conf_mat[i,:] = conf_mat[i,:]/sum(conf_mat[i,:])\n",
        "\n",
        "plt.imshow(conf_mat, cmap='hot')\n",
        "\n",
        "plt.xticks([0,1,2,3,4,5],class_names)\n",
        "plt.yticks([0,1,2,3,4,5],class_names)\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd_lkTdoUaOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(1)  # pause a bit so that plots are updated\n",
        "    \n",
        "def visualize_model(model, num_images=8):\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(dataloaders['test']):\n",
        "        #move to GPU\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "        \n",
        "        outputs = model(images)\n",
        "        \n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "       \n",
        "\n",
        "        for j in range(images.size()[0]):\n",
        "            # if preds[j] == labels[j]:\n",
        "            #   continue \n",
        "            images_so_far += 1\n",
        "            #ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "  \n",
        "            #plt.axis('off')\n",
        "            #ax.set_title('class: {} predicted: {}'.format(class_names[labels.data[j]], class_names[preds[j]]))\n",
        "            print('class: {} predicted: {}'.format(class_names[labels.data[j]], class_names[preds[j]]))\n",
        "            imshow(images.cpu().data[j])\n",
        "\n",
        "            if images_so_far == num_images:\n",
        "              return"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUYa3X4ZrCqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irbulScrVkRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import interpolate\n",
        "x = np.arange(5, 25)\n",
        "x_train = np.arange(0,25)\n",
        "x1 = [5, 10, 15, 20, 25]\n",
        "f_loss = interpolate.interp1d(x1, val_loss_list)\n",
        "f_accuracy = interpolate.interp1d(x1, val_acc_list)\n",
        "\n",
        "\n",
        "val_acc = f_accuracy(x)   # use interpolation function returned by `interp1d`\n",
        "val_loss = f_loss(x)\n",
        "\n",
        "train_loss_list\n",
        "train_acc_list\n",
        "val_loss\n",
        "val_acc\n",
        "\n",
        "\n",
        "plt.plot(x_train, train_loss_list)\n",
        "plt.plot(x, val_loss)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()\n",
        "plt.figure()\n",
        "plt.plot(x_train, train_acc_list)\n",
        "plt.plot(x, val_acc)\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyDPGRCgtfth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def test_new(dataloader_new, model, criterion, repeats=2):\n",
        "#   model.eval()\n",
        "  \n",
        "#   test_loss = 0.0\n",
        "#   test_acc = 0.0\n",
        "#   f1_score = 0.0\n",
        "#   f1_score_w = 0.0\n",
        "#   conf_mat = np.zeros([len(class_names),len(class_names)])\n",
        "#   with torch.no_grad():\n",
        "#     for itr in range(repeats):\n",
        "#       for batch_idx, (images, labels) in enumerate(dataloader_new):\n",
        "#         #move to GPU\n",
        "#         images, labels = images.cuda(), labels.cuda()\n",
        "#         #print(images.shape())\n",
        "\n",
        "#         #forward\n",
        "#         outputs = model.forward(images)\n",
        "#         _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "#         predlabels = preds.cpu().numpy()\n",
        "#         labels_num = labels.cpu().numpy()\n",
        "#         for ind,label in enumerate(labels_num):\n",
        "#           conf_mat[label,predlabels[ind]] = conf_mat[label,predlabels[ind]] + 1\n",
        "        \n",
        "\n",
        "#         loss = criterion(outputs, labels)\n",
        "\n",
        "#         _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "#         test_loss += loss.item()\n",
        "#         test_acc += torch.sum(preds == labels).item()\n",
        "          \n",
        "#         f1_score += metric.f1_score(labels_num, predlabels,labels=[0,1,2,3,4,5], average='weighted', zero_division='warn')\n",
        "#         f1_score_w += metric.f1_score(labels_num, predlabels,labels=[0,1,2,3,4,5], average='macro', zero_division='warn')\n",
        "\n",
        "#     test_loss /= (dataset_sizes['test']*repeats)\n",
        "#     test_acc /= (dataset_sizes['test']*repeats)\n",
        "#     f1_score /= (dataset_sizes['test']*repeats)\n",
        "\n",
        "\n",
        "#     print('Test Loss: %.4f Test Accuracy %.4f Weighted: %.4f Macro: %.4f' % (test_loss, test_acc, f1_score, f1_score_w))\n",
        "#     return test_loss, test_acc, conf_mat\n",
        "\n",
        "# root_path_new = 'our_dataset/' #If your data is in a different folder, set the path accodordingly\n",
        "\n",
        "# new_dataset_test = Dataset_Gary(root_path_new, fold=\"test\",\n",
        "# \t\t\t\t transform=transforms.Compose([\n",
        "#         transforms.Resize((384, 512)),\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "#     ]), target_transform=None)\n",
        "\n",
        "# # defining data loaders to load data using image_datasets and transforms, here we also specify batch size for the mini batch\n",
        "\n",
        "# dataloader_test_new = torch.utils.data.DataLoader(new_dataset_test, batch_size=BATCH_SIZE,\n",
        "#                                              shuffle=True, num_workers=4)\n",
        "\n",
        "# dataloaders = {'train': dataloader_train, 'test': dataloader_test_new, 'val':dataloader_val}\n",
        "\n",
        "# dataset_size_train = len(image_datasets_train)\n",
        "# dataset_size_val = len(image_datasets_val)\n",
        "# dataset_size_test_new = len(new_dataset_test)\n",
        "\n",
        "# dataset_sizes = {'train': dataset_size_train, 'test': dataset_size_test_new, 'val':dataset_size_val}\n",
        "\n",
        "# t1_new,t2_new,conf_mat_new = test_new(dataloader_test_new,model, criterion)\n",
        "# print('Conf Mat\\n',conf_mat_new)\n",
        "\n",
        "# def imshow(inp, title=None):\n",
        "#     \"\"\"Imshow for Tensor.\"\"\"\n",
        "#     inp = inp.numpy().transpose((1, 2, 0))\n",
        "#     inp = np.clip(inp, 0, 1)\n",
        "#     plt.axis(\"off\")\n",
        "#     plt.imshow(inp)\n",
        "#     if title is not None:\n",
        "#         plt.title(title)\n",
        "#     plt.pause(1)  # pause a bit so that plots are updated\n",
        "    \n",
        "# def visualize_model_new(dataloader, model, num_images=8):\n",
        "#     images_so_far = 0\n",
        "#     fig = plt.figure()\n",
        "\n",
        "#     for batch_idx, (images, labels) in enumerate(dataloader):\n",
        "#         #move to GPU\n",
        "#         images, labels = images.cuda(), labels.cuda()\n",
        "        \n",
        "#         outputs = model(images)\n",
        "        \n",
        "#         _, preds = torch.max(outputs.data, 1)\n",
        "       \n",
        "\n",
        "#         for j in range(images.size()[0]):\n",
        "#             #if preds[j] == labels[j]:\n",
        "#              # continue \n",
        "#             images_so_far += 1\n",
        "#             #ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "  \n",
        "#             #plt.axis('off')\n",
        "#             #ax.set_title('class: {} predicted: {}'.format(class_names[labels.data[j]], class_names[preds[j]]))\n",
        "#             print('class: {} predicted: {}'.format(class_names[labels.data[j]], class_names[preds[j]]))\n",
        "#             imshow(images.cpu().data[j])\n",
        "\n",
        "#             if images_so_far ==20:\n",
        "#               return\n",
        "# visualize_model_new(dataloader_test_new,model)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}